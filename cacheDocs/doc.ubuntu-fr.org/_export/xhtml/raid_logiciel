<!DOCTYPE html>
<html lang="fr" dir="ltr">
<head>
  <meta charset="utf-8" />
  <title>raid_logiciel</title>
<meta name="generator" content="DokuWiki"/>
<meta name="robots" content="index,follow"/>
<meta name="date" content="2015-04-03T03:59:23+0200"/>
<meta name="keywords" content="sauvegarde,securite,systeme,raid"/>
<link rel="search" type="application/opensearchdescription+xml" href="../../lib/exe/opensearch.php" title="Documentation Ubuntu Francophone"/>
<link rel="start" href="../../index.html"/>
<link rel="contents" href="../../raid_logiciel?do=index" title="Plan du site"/>
<link rel="alternate" type="application/rss+xml" title="Derniers changements" href="../../feed.php"/>
<link rel="alternate" type="application/rss+xml" title="Namespace actuel" href="../../feed.php?mode=list&amp;ns="/>
<link rel="alternate" type="text/html" title="HTML brut" href="raid_logiciel"/>
<link rel="alternate" type="text/plain" title="Wiki balise" href="../raw/raid_logiciel"/>
<link rel="canonical" href="../../raid_logiciel"/>
<link rel="stylesheet" type="text/css" href="../../lib/exe/css.php?t=ubuntu-2010&amp;tseed=4af22dedc19f28c99fa67afabbb173df"/>
<script type="text/javascript">/*<![CDATA[*/var NS='';var JSINFO = {"id":"raid_logiciel","namespace":""};
/*!]]>*/</script>
<script type="text/javascript" charset="utf-8" src="../../lib/exe/js.php?tseed=4af22dedc19f28c99fa67afabbb173df"></script>
</head>
<body>
<div class="dokuwiki export">
<!-- TOC START -->
<div id="dw__toc">
<h3 class="toggle">Table des matières</h3>
<div>

<ul class="toc">
<li class="level1"><div class="li"><a href="raid_logiciel#introduction_-_qu_est-il_possible_de_faire">Introduction - Qu&#039;est-il possible de faire ?</a></div>
<ul class="toc">
<li class="level2"><div class="li"><a href="raid_logiciel#ce_que_raid_n_est_pas">Ce que RAID n&#039;est pas</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#les_types_de_raid">Les types de RAID</a></div></li>
</ul>
</li>
<li class="level1"><div class="li"><a href="raid_logiciel#mise_en_œuvre">Mise en œuvre</a></div></li>
<li class="level1"><div class="li"><a href="raid_logiciel#pre-requis">Pré-requis</a></div></li>
<li class="level1"><div class="li"><a href="raid_logiciel#installation">Installation</a></div>
<ul class="toc">
<li class="level2"><div class="li"><a href="raid_logiciel#installation_de_mdadm">Installation de mdadm</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#configuration_des_disques_durs">Configuration des disques durs</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#construction_du_volume_raid">Construction du volume RAID</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#finalisation">Finalisation</a></div></li>
</ul>
</li>
<li class="level1"><div class="li"><a href="raid_logiciel#utilisationconfiguration">Utilisation/Configuration</a></div>
<ul class="toc">
<li class="level2"><div class="li"><a href="raid_logiciel#que_faire_pour_agrandir_l_array_-_ajouter_un_disque">Que faire pour agrandir l&#039;array ? - Ajouter un disque</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#que_faire_lorsqu_un_des_composants_de_l_array_vient_a_defaillir">Que faire lorsqu&#039;un des composants de l&#039;Array vient à défaillir ?</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#comment_migrer_les_donnees_vers_une_nouvelle_machine">Comment migrer les données vers une nouvelle machine ?</a></div></li>
</ul>
</li>
<li class="level1"><div class="li"><a href="raid_logiciel#problemes_solutions_courantes">Problèmes &amp; solutions courantes</a></div>
<ul class="toc">
<li class="level2"><div class="li"><a href="raid_logiciel#probleme_de_taille_de_block_superblock">Problème de taille de block &amp; superblock</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#device_or_ressource_busy">Device or ressource busy ...</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#md127">md127</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#droits_d_ecriture">Droits d&#039;écriture</a></div></li>
</ul>
</li>
<li class="level1"><div class="li"><a href="raid_logiciel#des_idees_pour_aller_plus_loin">Des idées pour aller plus loin</a></div>
<ul class="toc">
<li class="level2"><div class="li"><a href="raid_logiciel#decoupage_du_volume_avec_lvm">Découpage du volume avec LVM</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#la_combinaison_des_niveaux_de_raid">La combinaison des niveaux de RAID</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#un_disque_de_sparevotre_roue_de_secours_en_cas_de_defaillance">Un disque de spare : votre roue de secours en cas de défaillance</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#test">Test</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#supervision_du_raid">Supervision du RAID</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#creation_d_un_raid_sans_avoir_tous_les_disques">Création d&#039;un RAID sans avoir tous les disques</a></div></li>
<li class="level2"><div class="li"><a href="raid_logiciel#creation_d_un_raid1_sans_avoir_tous_les_disques_et_sans_copie">Création d&#039;un RAID1 sans avoir tous les disques et sans copie</a></div></li>
</ul>
</li>
<li class="level1"><div class="li"><a href="raid_logiciel#un_peu_de_reference">Un peu de référence</a></div></li>
</ul>
</div>
</div>
<!-- TOC END -->
<div class="tags"><span>
	<a href="../../sauvegarde" class="wikilink1" title="sauvegarde" rel="tag">sauvegarde</a>,
	<a href="http://doc.ubuntu-fr.org/securite" class="wikilink1" title="securite" rel="tag">sécurité</a>,
	<a href="../../systeme" class="wikilink1" title="systeme" rel="tag">système</a>,
	<a href="../../raid" class="wikilink1" title="raid" rel="tag">raid</a>
</span></div>
<hr />

<h1 class="sectionedit1" id="raid_logiciel_avec_mdadm">RAID logiciel avec mdadm</h1>
<div class="level1">

<p>
<p><div class="notetip"><strong>Il est aussi possible de créer des RAID sans l&#039;utilisation des lignes de commandes via l&#039;application graphique <a href="../../gnome-disk-utility" class="wikilink1" title="gnome-disk-utility">palimpsest</a> !</strong> (Il faut quand même installer mdadm et renseigner le fichier mdadm.conf avec <strong>ARRAY /dev/mdx devices=/dev/… /dev/… auto=yes</strong> sinon votre raid ne démarrera pas tout seul au boot du système) 
</div></p>
</p>

</div>
<!-- EDIT1 SECTION "RAID logiciel avec mdadm" [52-461] -->
<h2 class="sectionedit2" id="introduction_-_qu_est-il_possible_de_faire">Introduction - Qu&#039;est-il possible de faire ?</h2>
<div class="level2">

<p>
Vous venez de terminer une installation d&#039;Ubuntu et voulez protéger vos données ou améliorer les performances en utilisant un système RAID (1, 5 et 6 pour la sécurité des donnés + perfs; 0 pour les perfs brutes au prix d&#039;un risque accru de perte de donnés). <br/>

Le RAID utilise une logique très simple. Pour sauvegarder efficacement les données, il suffit de les copier à plusieurs endroits. <br/>

Le RAID permet donc d&#039;utiliser les performances de plusieurs disques de manière optimale tout en diminuant les risques de perte de données.
</p>

</div>
<!-- EDIT2 SECTION "Introduction - Qu'est-il possible de faire ?" [462-1067] -->
<h3 class="sectionedit3" id="ce_que_raid_n_est_pas">Ce que RAID n&#039;est pas</h3>
<div class="level3">

<p>
Le RAID n&#039;est pas une solution de sauvegarde, il s&#039;agit d&#039;une solution qui permet un rétablissement rapide de la situation lors d&#039;un cas de figure favorable.
Les deux (ou plus) disques utilisés étant souvent de la même époque, de la même marque, et même de la même série, il se peut que vous n&#039;ayez pas de chance et que plus d&#039;un disque grille à la fois, dans ce cas, il est possible que vous ne puissiez pas récupérer la moindre bribe de données …
Lors d&#039;un événement qui conduirait à des dégâts électriques tous les composants de votre PC peuvent griller en même temps … Ce genre de dégâts est fréquent si votre alimentation est dite &quot;NONAME&quot; c&#039;est-à-dire une alimentation souvent vendue avec les ordinateurs pré-assemblés. La remplacer par une Alim de marque reconnue permet de baisser ce risque énormément à tel point qu&#039;il en devient négligeable. Malgré tout une sauvegarde externe reste très vivement conseillée.
</p>

<p>
Dans le cas d&#039;un RAID 0, il ne s&#039;agit aucunement d&#039;une solution de sauvegarde, bien au contraire, le fait d&#039;étaler les données sur plusieurs disques augmente certes les performances, mais il en résulte une plus grande chance de panne. En effet si un seul des disques d&#039;un groupe RAID 0 grille, l&#039;intégralité des données devient illisible !
Ce type de RAID est donc utile seulement dans les cas où les données sont non cruciales mais dont les besoins de performances de lecture/écriture sont importants. (Partition système ou partition dite &quot;Scratch area&quot; c&#039;est-à-dire endroit où est fait le travail courant avant d&#039;être stocké plus en sécurité)
</p>

</div>
<!-- EDIT3 SECTION "Ce que RAID n'est pas" [1068-2719] -->
<h3 class="sectionedit4" id="les_types_de_raid">Les types de RAID</h3>
<div class="level3">
<ul>
<li class="level1"><div class="li"> RAID 0: 2 disques minimum - &quot;Taille du plus petit disque&quot; x &quot;nombre de disques&quot; - Ce type de RAID ne protège pas du tout vos données, mais obtient les performances maximales de vos disques. Ce mode permet en effet de combiner plusieurs disques en un seul. Les données seront distribuées entre chaque disque (le nombre de disques utilisables est illimité, mais les risques de pannes augmentent, en toute logique, proportionnellement) ce qui permet de presque doubler les performances avec deux disques, presque tripler avec 3, etc … (&quot;Vitesse du disque le plus lent&quot; x &quot;nombre de disques&quot;)</div>
</li>
<li class="level1"><div class="li"> RAID 1: 2 disques minimum - Taille du plus petit disque - En RAID 1 vos données sont copiées sur deux disques ou plus. C&#039;est-à-dire que chaque disque sera l&#039;exacte copie du premier. Si l&#039;un d&#039;eux grille, il suffit de le remplacer pour créer une nouvelle copie sur ce nouveau disque. Côté performances, en écriture, elles seront les mêmes qu&#039;avec un seul disque (le plus lent du groupe). En lecture les performances sur la copie d&#039;un seul fichier devraient être proches de la vitesse d&#039;un seul disque, mais vous pourrez lire à pleine vitesse autant de fichiers qu&#039;il y a de disques en miroir (Exemple: Avec 3 disques identiques vous pouvez lire un fichier à 120 mo/s tout comme 3 fichiers à la fois, toujours à 120 mo/s par fichier)</div>
</li>
<li class="level1"><div class="li"> RAID 5: 3 disques minimum - &quot;Taille du plus petit disque&quot; x (&quot;Nombre de disques&quot; - 1) - Le RAID 5 est un mélange de RAID 0 et de RAID 1. Les fichiers sont à la fois coupés en plusieurs disques pour optimiser les performances et à la fois clonés de telle manière à ce qu&#039;ils soient récupérables lors de la perte d&#039;un disque. La vitesse est d&#039;environ celle de <em>&quot;vitesse du pire disque&quot; x (&quot;Nombre de disques&quot; - 1)</em> que ce soit en lecture ou écriture, même si les performances en écriture peuvent être limitées par la puissance du CPU quand le nombre de disques est élevé (+ de 6 sur un PC actuel haut de gamme). Vous pouvez ajouter autant de disques que vous le souhaitez, mais le nombre de disques pouvant tomber en panne avant la perte totale des données du groupe restera toujours de 1.</div>
</li>
<li class="level1"><div class="li"> RAID 6: 4 disques minimum - &quot;Taille du plus petit disque&quot; x (&quot;Nombre de disques&quot; - 2) - Même chose que le RAID 5 sauf que 2 disques peuvent griller avant de perdre toutes les données contenues. Cette version du RAID est faite pour ceux utilisant un grand nombre de disques (5 ou plus) en RAID 5</div>
</li>
<li class="level1"><div class="li"> RAID 10: 4 disques minimum (par paire) - 2 x &quot;Taille du plus petit disque&quot; -  Le RAID 10 ou RAID 1+0 est le fait de créer deux (ou plus) RAID 1 que vous combinez ensuite en un RAID 0. Cette technique est automatisée par le mode RAID 10 qui fait le travail pour vous. Les performances en lecture sont du niveau d&#039;un RAID 0 de deux (ou plus) disques mais deux fichiers peuvent êtres accédés à pleine vitesse en même temps. En écriture les performances sont celles de deux disques. Ce mode est recommandé pour des performances optimales tout en ayant une copie de sauvegarde. Malgré tout sa complexité n&#039;en fait pas un mode recommandé ni pour les débutants, ni pour les particuliers en général. Beaucoup préféreront le mode RAID 5 avec le même nombre de disques, qui malgré des performances légèrement moindres vous offre plus d&#039;espace utilisable.</div>
</li>
</ul>

<p>
Pour plus de détails, Wikipédia est bien fourni : <br/>

<a href="http://fr.wikipedia.org/wiki/RAID_(informatique)" class="interwiki iw_wpfr" title="http://fr.wikipedia.org/wiki/RAID_(informatique)">Les différents types de RAID</a>
</p>

</div>
<!-- EDIT4 SECTION "Les types de RAID" [2720-6196] -->
<h2 class="sectionedit5" id="mise_en_œuvre">Mise en œuvre</h2>
<div class="level2">

<p>
Tout ce qui suit fonctionne aussi bien avec la version serveur que la version Desktop d&#039;Ubuntu. <br/>

L&#039;exemple utilisé est un montage RAID 5 <strong>logiciel</strong>, mais la méthode pour les autres types de RAID logiciel est la même.<br/>

L&#039;avantage est que vous ne vous ruinez pas dans l&#039;achat d&#039;une carte fille supportant le RAID  5 et en quelques lignes de commandes vous avez l&#039;équivalent pour uniquement le prix des disques ! <br/>

Mdadm remplace aussi avantageusement l&#039;utilisation d&#039;un <a href="http://doc.ubuntu-fr.org/tutoriel/comment_utiliser_le_raid_onboard" class="wikilink1" title="tutoriel:comment_utiliser_le_raid_onboard">fake-raid</a> qui n&#039;offre généralement pas d&#039;aussi bonnes performances.<br/>

L&#039;utilisation de disques durs <abbr title="Serial Advanced Technology Attachment">SATA</abbr>, est plus que recommandée, car ils permettent une extraction à chaud (Hot Plug) pour un prix abordable. 
</p>

<p>
Le logiciel qui va nous permettre de remplir notre objectif s&#039;appelle <strong>mdadm</strong>.
</p>

<p>
<p><div class="noteclassic">
Si vous avez besoin de la prise en charge du RAID logiciel dès l&#039;installation de votre système, vous pouvez vous tourner vers
une iso <a href="../../installation_alternate#obtenir_une_iso_alternate" class="wikilink1" title="installation_alternate">alternate</a> ou une iso serveur.

</div></p>
</p>

</div>
<!-- EDIT5 SECTION "Mise en œuvre" [6197-7288] -->
<h2 class="sectionedit6" id="pre-requis">Pré-requis</h2>
<div class="level2">
<ol>
<li class="level1"><div class="li"> Il faut les droits root/administrateur</div>
</li>
<li class="level1"><div class="li"> Il faut un noyau supérieur à 2.6 (ne devrait pas être difficile à atteindre)</div>
</li>
<li class="level1"><div class="li"> Connexion Internet configurée et activée (utilisez le <abbr title="Dynamic Host Configuration Protocol">DHCP</abbr>, si possible, cela évite de se casser la tête). </div>
</li>
<li class="level1"><div class="li"> Configurez votre fichier /etc/apt/sources.list pour qu&#039;Ubuntu aille tout chercher sur Internet. (déjà fait par défaut à priori)</div>
</li>
<li class="level1"><div class="li"> Ayez au moins 2 disques durs (cas du RAID 0 ou 1) ou 3 disques durs (cas du RAID 5) ou 4 disques durs (cas du RAID 6 et RAID 10)</div>
</li>
<li class="level1"><div class="li"> … branchés sur des contrôleurs <abbr title="Integrated Drive Electronics">IDE</abbr> Sata/P-ata/SCSI reconnus par Ubuntu (C&#039;est à dire la quasi totalité)</div>
</li>
<li class="level1"><div class="li"> Il est recommandé que les disques soient de même taille, mais ce n&#039;est pas indispensable, vous pouvez partitionner vos disques de telle manière que chaque disque ait une partition de la taille du disque le plus petit, le restant des disques pourra être utilisé en mode conventionnel &quot;NON-RAID&quot;</div>
</li>
</ol>

</div>
<!-- EDIT6 SECTION "Pré-requis" [7289-8244] -->
<h2 class="sectionedit7" id="installation">Installation</h2>
<div class="level2">

</div>
<!-- EDIT7 SECTION "Installation" [8245-8270] -->
<h3 class="sectionedit8" id="installation_de_mdadm">Installation de mdadm</h3>
<div class="level3">

<p>
Il suffit d&#039;<a href="../../tutoriel/comment_installer_un_paquet" class="wikilink1" title="tutoriel:comment_installer_un_paquet">installer le paquet</a> <strong><a href="apt://mdadm" class="interwiki iw_apt" title="apt://mdadm">mdadm</a></strong>.
</p>

</div>
<!-- EDIT8 SECTION "Installation de mdadm" [8271-8404] -->
<h3 class="sectionedit9" id="configuration_des_disques_durs">Configuration des disques durs</h3>
<div class="level3">

<p>
Comme indiqué ci-dessus dans les pré-requis, il faut au moins 3 disques durs pour faire du RAID 5. Dans cet exemple j&#039;ai pris 4 disques, mais l&#039;opération est la même si vous en utilisez plus ou moins que moi.
</p>

<p>
Il faut partitionner les disques durs que nous allons utiliser grâce à l&#039;utilitaire fdisk. Ici je vous guide pour un disque, à vous de le faire autant de fois que vous voulez utiliser de disques. Vous pouvez aussi utiliser <a href="../../gparted" class="wikilink1" title="gparted">Gparted</a>
</p>
<pre class="code">sudo fdisk /dev/sdX</pre>

<p>
Il faut comprendre que le `sdX` représente votre disque dur et que `X` représente sa lettre. Par exemple `sda`, `sdb`, `sdc`, etc… (vous pouvez utiliser <a href="../../gnome-disk-utility" class="wikilink1" title="gnome-disk-utility">Gnome-disk-utility</a> pour connaître le &quot;nom&quot; de votre disque.)
</p>

<p>
Info : Pour des partitions de plus de 2.2To, il faut utiliser &quot;gdisk&quot;, de la même manière
</p>
<pre class="code">sudo gdisk /dev/sdX</pre>

<p>
Choisir un type de table de partition &quot;GPT&quot;, puis suivre a nouveau ce tuto
</p>

<p>
Vous obtiendrez (grâce à l&#039;option `m`) les lignes suivantes : 
</p>

<p>
<a href="../../_detail/securite/menu_fdisk.gif?id=raid_logiciel" class="media" title="securite:menu_fdisk.gif"><img src="../../_media/securite/menu_fdisk.gif" class="media" alt="" /></a>
</p>

<p>
Il faut donc appliquer l&#039;option `n` comme montré ci-dessus pour créer une nouvelle partition.
</p>

<p>
fdisk vous demande alors le type de partition (p pour primaire ou e pour étendue).<br/>

Nous n&#039;allons créer qu&#039;une seule partition par disque, nous choisirons donc le type primaine : &#039;p&#039;
</p>

<p>
Vous entrez ensuite dans le processus de création de partition étendue : 
</p>

<p>
<a href="../../_detail/securite/creation.1.gif?id=raid_logiciel" class="media" title="securite:creation.1.gif"><img src="../../_media/securite/creation.1.gif" class="media" alt="" /></a>
</p>

<p>
Tapez `1` comme montré ci-dessus
</p>

<p>
<a href="../../_detail/securite/creation.2.gif?id=raid_logiciel" class="media" title="securite:creation.2.gif"><img src="../../_media/securite/creation.2.gif" class="media" alt="" /></a>
</p>

<p>
Tapez sur la touche `Entrée`
</p>

<p>
<a href="../../_detail/securite/creation.3.gif?id=raid_logiciel" class="media" title="securite:creation.3.gif"><img src="../../_media/securite/creation.3.gif" class="media" alt="" /></a>
</p>

<p>
Tapez encore sur la touche `Entrée`
</p>

<p>
Tapez sur la touche &#039;t&#039; pour changer le type de partition.
</p>

<p>
Tapez &#039;fd&#039; (Valeur hexadécimale correspondant à &quot;Linux Raid Autodetect&quot;) puis `Entrée` afin de valider.
</p>

<p>
Enfin, validez les modifications en tapant `w` : 
</p>

<p>
<a href="../../_detail/securite/validation.gif?id=raid_logiciel" class="media" title="securite:validation.gif"><img src="../../_media/securite/validation.gif" class="media" alt="" /></a>
</p>

<p>
Vous venez de créer une partition primaire sur votre disque /dev/sdX
</p>

</div>
<!-- EDIT9 SECTION "Configuration des disques durs" [8405-10346] -->
<h3 class="sectionedit10" id="construction_du_volume_raid">Construction du volume RAID</h3>
<div class="level3">

<p>
Nous pouvons maintenant utiliser mdadm pour construire notre volume RAID 5 : 
</p>
<pre class="code">sudo mdadm --create /dev/md0 --level=5 --assume-clean --raid-devices=4 /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1</pre>

<p>
<strong>sudo</strong> permet de dire que le programme que nous allons exécuter aura les droits administrateur
<strong>mdadm</strong> est le nom du programme à utiliser (oui j&#039;explique même pour ceux qui ne sont pas adeptes de la ligne de commande)
<strong>–create /dev/md0</strong> permet de donner un nom à votre RAID. Ceci est le disque dur virtuel que vous êtes en train de créer à partir de vos disques
<strong>–level=5</strong> devra être modifié par le type de RAID que vous souhaitez utiliser (0,1,5,6,10). Exemple: –level=1 <br/>

<strong>–assume-clean</strong> permet de dire à mdadm que nos disques sont vides. Ce qui permet de passer l&#039;étape de synchronisation des disques.
<strong>–raid-devices=4</strong> devra être modifié pour donner le nombre de disques que vous souhaitez utiliser (ici 4, vous 2 ou 3 ou 5, etc)
<strong>/dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1</strong> il s&#039;agit de la liste des partitions que je dois ajouter à mon RAID. À vous de les adapter à votre configuration. Aidez-vous de <a href="../../gnome-disk-utility" class="wikilink1" title="gnome-disk-utility">Gnome-disk-utility</a> si trou de mémoire ^^
</p>

<p>
<p><div class="notehelp">Si cette commande échoue avec un message d&#039;erreur parlant de md0, c&#039;est parce que des modules n&#039;ont pas été ajoutés automatiquement au noyau (cela nécessite un redémarrage après installation du paquet mdadm). De ce fait, effectuer :
</p>
<pre class="code">sudo modprobe raid5
sudo modprobe md</pre>

<p>
Si l&#039;erreur persiste, faire au redémarrage suivant :
</p>
<pre class="code">sudo echo raid5 &gt;&gt; /etc/modules
sudo echo md &gt;&gt; /etc/modules</pre>

<p>
On trouvera aussi des informations intéressantes dans l&#039;article <a href="../../installation/raid1_software" class="wikilink1" title="installation:raid1_software">raid1_software</a>.

</div></p>
</p>

<p>
On termine cette construction par la daemonisation du volume RAID, c&#039;est-à-dire que nous allons faire en sorte que le système charge le volume à chaque démarrage : 
</p>
<pre class="code">sudo mdadm --daemonise /dev/md0</pre>

<p>
<p><div class="notehelp"> Si la commande ci-dessus renvoie un message du type :
</p>
<pre class="code">mdadm: --daemonise does not set the mode, and so cannot be the first option.</pre>

<p>
essayez la commande suivante :
</p>
<pre class="code">sudo mdadm --monitor --daemonise /dev/md0</pre>

<p>

</div></p>
</p>

<p>
On peut maintenant demander quelques détails à notre disque virtuel :
</p>
<pre class="code">sudo fdisk -l
sudo mdadm --detail /dev/md0</pre>

</div>
<!-- EDIT10 SECTION "Construction du volume RAID" [10347-12725] -->
<h3 class="sectionedit11" id="finalisation">Finalisation</h3>
<div class="level3">

<p>
Il reste quelques modifications à effectuer : 
</p>
<ol>
<li class="level1"><div class="li"> Il faut formater le volume RAID nouvellement créé  : </div>
</li>
</ol>
<pre class="code">sudo mkfs.ext4 /dev/md0</pre>
<ol>
<li class="level1"><div class="li"> Déclarez ce volume dans `fstab` pour que le système le monte au démarrage (le système de fichier, pas le volume en lui même). Pour ce faire <a href="../../tutoriel/comment_modifier_un_fichier" class="wikilink1" title="tutoriel:comment_modifier_un_fichier">Editez le fichier</a> <strong>/etc/fstab</strong> et ajoutez à sa fin la ligne : </div>
</li>
</ol>
<pre class="code">/dev/md0 	/media/raid	ext4	defaults 	0	1</pre>

<p>
Cela signifie que le système montera au démarrage le contenu du volume RAID dans le dossier /media/raid.
</p>
<ol>
<li class="level1"><div class="li"> Il ne reste plus qu&#039;à créer le dossier /media/raid grâce à la commande mkdir : </div>
</li>
</ol>
<pre class="code">sudo mkdir /media/raid</pre>

</div>
<!-- EDIT11 SECTION "Finalisation" [12726-13445] -->
<h2 class="sectionedit12" id="utilisationconfiguration">Utilisation/Configuration</h2>
<div class="level2">

</div>
<!-- EDIT12 SECTION "Utilisation/Configuration" [13446-13484] -->
<h3 class="sectionedit13" id="que_faire_pour_agrandir_l_array_-_ajouter_un_disque">Que faire pour agrandir l&#039;array ? - Ajouter un disque</h3>
<div class="level3">

<p>
Une fois les disques connectés et les partitions créées avec fdisk, il suffit de les ajouter :
</p>
<pre class="code">sudo mdadm --manage /dev/md0 --add /dev/sdf1</pre>

<p>
Ensuite étendre l&#039;array sur ces nouvelles partitions :
</p>
<pre class="code">sudo mdadm --grow /dev/md0 --raid-devices=5</pre>

<p>
Et enfin il vous faudra agrandir votre partition ext4 (ou similaire) via resize2fs.
</p>
<pre class="code">sudo resize2fs /dev/md0</pre>

</div>
<!-- EDIT13 SECTION "Que faire pour agrandir l'array ? - Ajouter un disque" [13485-13948] -->
<h3 class="sectionedit14" id="que_faire_lorsqu_un_des_composants_de_l_array_vient_a_defaillir">Que faire lorsqu&#039;un des composants de l&#039;Array vient à défaillir ?</h3>
<div class="level3">

<p>
Ne paniquez pas ! Vous n&#039;avez pas perdu de données.
L&#039;objectif maintenant est d&#039;identifier le disque dur défaillant, même si le disque ne tombe pas en panne physiquement, il peut défaillir. (Un bon outil de diagnostic est le visualiseur de données SMART de <a href="../../gnome-disk-utility" class="wikilink1" title="gnome-disk-utility">Gnome-disk-utility</a> ou smartctl dans <a href="../../smartmontools" class="wikilink1" title="smartmontools">SMARTMonTools</a>)
Maintenant que vous avez identifié le disque dur défectueux, il faut le déclarer comme tel. 
</p>

<p>
1. Pour cela, on utilise mdadm :
</p>
<pre class="code">mdadm --manage /dev/md0 --set-faulty /dev/sdb1</pre>

<p>
Explication :
</p>

<p>
On utilise toujours le paramètre `–manage` de mdadm pour gérer le volume RAID.
On utilise l&#039;option `–set-faulty` pour déclarer le disque dur `/dev/sdb1` du volume RAID `/dev/md0` comme défaillant.
</p>

<p>
2. Une fois déclaré défaillant, le disque dur est écarté du volume RAID. Il faut maintenant le désactiver pour pouvoir le retirer : 
</p>
<pre class="code">mdadm --manage /dev/md0 --remove /dev/sdb1</pre>

<p>
Vous pouvez maintenant retirer le disque défaillant en toute sécurité et le remplacer par un disque sain.
</p>

<p>
3. Une fois le remplacement effectué, il faut ajouter un disque sain dans le volume RAID pour bénéficier à nouveau de la tolérance de panne (cette opération doit être précédée du partitionnement du nouveau disque, aidez-vous des descriptions faites plus haut) :
</p>
<pre class="code">mdadm --manage /dev/md0 --add /dev/sdb1</pre>

<p>
Maintenant vous devez patienter, le temps que le volume Raid se reconstruise. Pendant cette phase de reconstruction les performances peuvent être altérées. Mais la reconstruction ralentit si vous avez besoin des disques.
</p>

</div>
<!-- EDIT14 SECTION "Que faire lorsqu'un des composants de l'Array vient à défaillir ?" [13949-15624] -->
<h3 class="sectionedit15" id="comment_migrer_les_donnees_vers_une_nouvelle_machine">Comment migrer les données vers une nouvelle machine ?</h3>
<div class="level3">

<p>
Cette partie va montrer comment migrer les données d&#039;un RAID à un autre RAID. Je vais considérer qu&#039;il s&#039;agit ici de la création d&#039;une nouvelle machine pour recouvrir tous les aspects du problème.
Il faut d&#039;abord créer le nouveau RAID comme décrit dans la partie précédente. Et ré-assembler le RAID existant de façon à les faire cohabiter le temps de la copie des données.
Pour cela il faut créer un nouveau fichier FIFO mais pour ne pas rentrer en conflit avec le fichier existant nous allons lui donner l&#039;identifiant 1 :
</p>
<pre class="code">mknod /dev/md1 b 9 1</pre>

<p>
Ensuite il ne reste plus qu&#039;à démarrer le vieux RAID comme suit :
</p>
<pre class="code">mdadm -A /dev/md1 --update=super-minor -m0 /dev/sd... /dev/sd...</pre>

<p>
La commande précédente demande l&#039;assemblage en mettant à jour les informations d&#039;identification. Le paramètre -mO s&#039;assure que nous utiliserons que les disques/partitions qui avaient un identifiant 0.
</p>

<p>
Pour s&#039;assurer que tout s&#039;est bien passé vous pouvez afficher les informations mdadm :
</p>
<pre class="code">cat /proc/mdstat</pre>

<p>
La sortie devrait ressembler à cela :
</p>
<pre class="code">md1 : active raid5 sda[0] sdb[3] sde[2] sdf[1]
      1465159488 blocks level 5, 128k chunk, algorithm 2 [4/4] [UUUU]
      
md0 : active raid5 sdc[0] sdg[2] sdd[1]
      1953524992 blocks level 5, 128k chunk, algorithm 2 [3/3] [UUU]</pre>

<p>
Si vous voulez faire persister les informations sur ce RAID vous pouvez passer la commande suivante :
</p>
<pre class="code">mdadm --daemonise /dev/md1</pre>

</div>
<!-- EDIT15 SECTION "Comment migrer les données vers une nouvelle machine ?" [15625-17185] -->
<h2 class="sectionedit16" id="problemes_solutions_courantes">Problèmes &amp; solutions courantes</h2>
<div class="level2">

</div>
<!-- EDIT16 SECTION "Problèmes & solutions courantes" [17186-17231] -->
<h3 class="sectionedit17" id="probleme_de_taille_de_block_superblock">Problème de taille de block &amp; superblock</h3>
<div class="level3">

<p>
Si en faisant une vérification, vous obtenez ceci :
</p>
<pre class="code">La taille du système de fichiers (selon le superbloc) est de 7727257 blocs
La taille physique du périphérique est de 7727232 blocs
Le superbloc ou la table des partitions est peut-être corrompue !</pre>

<p>
ou ceci  (au boot par exemple):
</p>
<pre class="code">my_documents: The filesystem size (according to the superblock) is 7727257 blocks
The physical size of the device is 7727232 blocks
Either the superblock or the partition table is likely to be corrupt!

my_documents: UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY.
	(i.e., without -a or -p options)</pre>

<p>
Cela provient certainement du fait que vous avez construit le raid sans recréer un système de fichier par dessus !  Dans ce cas faites ceci :
</p>
<pre class="code">e2fsck -f /dev/mdX</pre>

<p>
 (où X est la partition raid) et <strong>sans</strong> interrompre, taper &#039;n&#039; et laisser continuer (si vous n&#039;avez pas de backup faites le avant, on ne sait jamais). Une fois fini faites :
</p>
<pre class="code">resize2fs /dev/mdX</pre>

<p>
Cela va redimensionner la partition en fonction des info du superblock. pour être sûr revérifier (via e2fsck) la partition et cela devrait aller sans aucun problème !
</p>

</div>
<!-- EDIT17 SECTION "Problème de taille de block & superblock" [17232-18453] -->
<h3 class="sectionedit18" id="device_or_ressource_busy">Device or ressource busy ...</h3>
<div class="level3">

<p>
Si, au démarrage, vous avec un message du genre :
</p>
<blockquote><div class="no">
fsck.ext3: Device or resource busy while trying to open /dev/sdbX<br/>
Filesystem mounted or opened exclusively by another program?</div></blockquote>

<p>
Alors que /dev/sdX est un membre du raid et n&#039;est pas lui-même présent dans fstab, cette solution peut peut-être vous aider : 
(on sauvegarde pour le cas où …)
</p>
<pre class="code">sudo mv /etc/blkid.tab /etc/blkid.tab.baktimeofday</pre>

<p>
Ensuite redémarrer cela devrait être résolu.
</p>

</div>
<!-- EDIT18 SECTION "Device or ressource busy ..." [18454-18953] -->
<h3 class="sectionedit19" id="md127">md127</h3>
<div class="level3">

<p>
Avec <a href="../../precise" class="wikilink1" title="precise"> Ubuntu 12.04</a>
</p>

<p>
Si votre RAID est non fonctionnel et reconnu comme /dev/md127
</p>

<p>
Cette erreur semble principalement apparaître lors d&#039;une création de volume RAID avec l’outil graphique  <a href="../../gnome-disk-utility" class="wikilink1" title="gnome-disk-utility">palimpsest</a> (inclus dans gnome-disk-utility).
</p>

<p>
Il faut commencer par récupérer le numéro de UUID de votre volume RAID. Pour ce faire, il faut que votre RAID soit monté avec l&#039;outil graphique puis depuis un terminal taper la commande suivante :
</p>
<pre class="code">sudo mdadm -Es</pre>

<p>
Vous devez avoir ce type de résultat avec le numéro de UUID :
</p>
<pre class="code">ARRAY [...] level=raid1 metadata=1.2 num-devices=2 UUID=ed684f7c:0756fe74:cd2238a8:62f7ed56 [...]</pre>

<p>
Déclarer votre volume RAID dans /etc/mdadm/mdadm.conf (Toujours avec vos valeurs et pas forcement md0 s&#039;il est utilisé par un autre disque) :
</p>
<pre class="code">ARRAY /dev/md0 level=raid1 metadata=1.2 num-devices=2 UUID=UUID de votre volume RAID</pre>

<p>
Exemple extrait d&#039;un des threads ci-dessous :
</p>
<pre class="code">ARRAY /dev/md0 level=raid1 metadata=1.2 num-devices=2 UUID=ed684f7c:0756fe74:cd2238a8:62f7ed56</pre>

<p>
Éventuellement ajouter votre volume dans  /etc/fstab (pour le montage au démarrage du système) après avoir créé votre point de montage (ici →/media/VolumeRAID)  :
</p>
<pre class="code">/dev/md0	/media/VolumeRAID	ext4	defaults	0	0</pre>

<p>
Mettre à jour <a href="https://wiki.ubuntu.com/Initramfs" class="urlextern" title="https://wiki.ubuntu.com/Initramfs"  rel="nofollow">initramfs</a> afin de prendre en compte votre fichier mdadm.conf au démarrage :
</p>
<pre class="code">sudo update-initramfs -u</pre>

<p>
De nombreux threads traitent de ce sujet (étonnamment toujours pas résolu !):
<p><div class="notetip">Ce phénomène est lié à la présence de la variable &#039;name=xxxx:0&#039; dans la ligne de configuration de mdadm.conf.
</p>

<p>
En supprimant cette variable de la ligne et après avoir mis à jour &#039;initramfs&#039;, le problème disparaît.

</div></p>
</p>

<p>
<a href="http://forum.ubuntu-fr.org/viewtopic.php?id=372346" class="urlextern" title="http://forum.ubuntu-fr.org/viewtopic.php?id=372346"  rel="nofollow">http://forum.ubuntu-fr.org/viewtopic.php?id=372346</a>
</p>

<p>
<a href="http://ubuntuforums.org/showthread.php?t=1764861" class="urlextern" title="http://ubuntuforums.org/showthread.php?t=1764861"  rel="nofollow">http://ubuntuforums.org/showthread.php?t=1764861</a>
</p>

<p>
<a href="http://ubuntuforums.org/showthread.php?t=1468064" class="urlextern" title="http://ubuntuforums.org/showthread.php?t=1468064"  rel="nofollow">http://ubuntuforums.org/showthread.php?t=1468064</a>
</p>

<p>
<a href="http://ubuntuforums.org/archive/index.php/t-1883173.html" class="urlextern" title="http://ubuntuforums.org/archive/index.php/t-1883173.html"  rel="nofollow">http://ubuntuforums.org/archive/index.php/t-1883173.html</a>
</p>

</div>
<!-- EDIT19 SECTION "md127" [18954-20984] -->
<h3 class="sectionedit20" id="droits_d_ecriture">Droits d&#039;écriture</h3>
<div class="level3">

<p>
Lorsque votre RAID est activé automatiquement au boot, il se peut qu&#039;en le montant avec le gestionnaire de fichier Nautilus, vous n&#039;ayez pas les droits d&#039;écriture.
</p>

<p>
Pour corriger cela, il faut d&#039;abord localiser le point de montage et vérifier les propriétés :
</p>
<pre class="code">ls -l /media
total 8
drwxr-xr-x 2 root root 4096 juil.  7 02:03 cdrom
drwxr-xr-x 3 root disk 4096 nov.  30 15:48 my_raid</pre>

<p>
On voit que le montage est réalisé sur &#039;/media/my_raid&#039; appartient à &#039;root&#039; et a pour groupe &#039;disk&#039;, mais que seul &#039;root&#039; peut écrire.
Il faut remédier à cela en intégrant votre utilisateur dans le groupe &#039;disk&#039; et en autorisant l&#039;écriture dans le RAID pour ce groupe.
</p>
<pre class="code">sudo adduser &lt;votre_nom&gt; disk
sudo chmod -R 775 /media/my_raid</pre>

<p>
Vous aurez maintenant, en tant que membre du groupe &#039;disk&#039;, le droit d&#039;écrire.
</p>

</div>
<!-- EDIT20 SECTION "Droits d'écriture" [20985-21851] -->
<h2 class="sectionedit21" id="des_idees_pour_aller_plus_loin">Des idées pour aller plus loin</h2>
<div class="level2">

</div>
<!-- EDIT21 SECTION "Des idées pour aller plus loin" [21852-21897] -->
<h3 class="sectionedit22" id="decoupage_du_volume_avec_lvm">Découpage du volume avec LVM</h3>
<div class="level3">

<p>
Lorsque l&#039;on crée un volume RAID, on se retrouve vite avec de capacités très importantes. Or, créer un seul système de ficher de 500 Go, voir beaucoup plus, n&#039;est pas forcement une bonne idée ! Pour pouvoir découper cet espace de stockage à volonté et pouvoir créer autant de système de fichier que nécessaire (et les redimensioner au besoin) il peut être très intéressant d&#039;utiliser, &quot;au dessus&quot; du RAID la fonctionnalité LVM :
</p>

<p>
<a href="../../lvm.1" class="wikilink1" title="lvm">lvm</a>
</p>

</div>
<!-- EDIT22 SECTION "Découpage du volume avec LVM" [21898-22395] -->
<h3 class="sectionedit23" id="la_combinaison_des_niveaux_de_raid">La combinaison des niveaux de RAID</h3>
<div class="level3">

<p>
Vous pouvez très bien combiner les niveaux de RAID. 
La manière la moins onéreuse de créer un RAID combiné est d&#039;effectuer plusieurs RAID matériels puis de les combiner entre eux au niveau logiciel. 
</p>

<p>
On pourra prendre comme exemple le RAID 1,0 qui fonctionne très bien.
Imaginons que nous ayons 6 disques durs de 30Go, plus un disque dur système et trois cartes-filles supportant le RAID 1. Créons donc trois ensembles RAID 1 (mirroring) qui feront tous 30Go. 
Appliquons ensuite un RAID 0 au niveau logiciel. 
On possède alors un seul ensemble de 90Go (3 x 30Go) et une tolérance de panne de trois disques durs (1 par unité RAID 1).
</p>

</div>
<!-- EDIT23 SECTION "La combinaison des niveaux de RAID" [22396-23105] -->
<h3 class="sectionedit24" id="un_disque_de_sparevotre_roue_de_secours_en_cas_de_defaillance">Un disque de spare : votre roue de secours en cas de défaillance</h3>
<div class="level3">

<p>
Pour ceux qui sont intéressés par la commande mdadm, sachez qu&#039;elle possède d&#039;autres options. L&#039;une de ses options permet notamment d&#039;ajouter un disque de spare, c&#039;est-à-dire un disque &quot;dormant&quot;, qui prend la relève dès qu&#039;un disque tombe en panne. Cela vous permet une plus grande tolérance de panne. 
</p>

<p>
Voici l&#039;option permettant de prendre en compte un disque de spare : 
</p>
<pre class="code">mdadm --create /dev/md0 --level=1 --raid-devices=2 --spare-devices=1 /dev/sdX</pre>

<p>
Par contre, si vous avez déjà un array RAID en service, sur sda2 et sdb2, et que vous voulez ajouter le spare sdc2 (préalablement partitionné à l&#039;identique avec sfdisk par exemple) :
<p><div class="noteclassic">Afin de créer un disque de spare, il nous faut lui donner le même partitionnement que les autres disques du RAID. Pour cela, la commande sfdisk va nous aider.
</div></p>
Une fois votre disque supplémentaire connecté, il vous faut créer les mêmes partitions, pour cela tapez en root dans un terminal (sudo -i, ou sudo bash je vous le rappelle) :
</p>
<pre class="code">sfdisk -d /dev/sda &gt; sda.out
sfdisk /dev/sdc &lt; sda.out</pre>

<p>
ou sda est le disque &quot;source&quot;, et sdc le disque &quot;target&quot;
</p>
<pre class="code">mdadm --manage /dev/md0 --add /dev/sdc2</pre>

<p>
Vérifiez alors en tapant :
</p>
<pre class="code">mdadm --detail /dev/md0</pre>

<p>
Et vous verrez votre nouveau disque sdc2 comme spare disk.
</p>

</div>
<!-- EDIT24 SECTION "Un disque de spare : votre roue de secours en cas de défaillance" [23106-24515] -->
<h3 class="sectionedit25" id="test">Test</h3>
<div class="level3">

<p>
Pour tester, et être sûr que tout fonctionne, faisons un test (qui revient à débrancher un disque) :
</p>
<pre class="code">mdadm --manage /dev/md0 --set-faulty /dev/sdb
mdadm --manage /dev/md0 --remove /dev/sdb</pre>

<p>
Alors le spare disque (ou le miroir…) prend le relais automatiquement.
Si vous n&#039;avez pas de spare, remettez le disque en service :
</p>
<pre class="code">mdadm --manage /dev/md0 --add /dev/sdb2</pre>

<p>
Constatez la reconstruction avec :
</p>
<pre class="code">cat /proc/mdstat</pre>

<p>
Chaque disque retiré puis remis fera une reconstruction complète. Pour un array de 40 Go, comptez 15 min pour atteindre les 100% (60 mo/s environ). Évitez de rebooter la machine pendant la progression.
</p>

<p>
Sans simuler la défaillance d&#039;un disque, voici un outil qui vous permettra de vérifier si vos disques sont bien synchronisés, le test sera long. voir <em>/usr/share/mdadm/checkarray  –help</em> pour plus d&#039;options.
</p>
<pre class="code">sudo /usr/share/mdadm/checkarray  /dev/md0</pre>

<p>
Pour ceux qui fouillent un peu, les fichiers de configurations sont
</p>
<ul>
<li class="level1"><div class="li">  file:///etc/default/mdadm </div>
</li>
<li class="level1"><div class="li">  file:///etc/mdadm/mdadm.conf</div>
</li>
</ul>

</div>
<!-- EDIT25 SECTION "Test" [24516-25622] -->
<h3 class="sectionedit26" id="supervision_du_raid">Supervision du RAID</h3>
<div class="level3">

<p>
Dans le fichier mdadm.conf ou lorsque l&#039;on utilise mdadm en mode monitoring il est possible de se faire envoyer un email lorsqu&#039;il y a un évènement qui se produit, c&#039;est bien, c&#039;est le comportement par défaut, mais si on n&#039;est pas sur un serveur (et même dans ce cas) ce n&#039;est pas toujours l&#039;idéal. Enfin, rien ne vous empêche d&#039;installer <a href="../../messagerie_intranet" class="wikilink1" title="messagerie_intranet">mailx</a>
</p>

<p>
L&#039;idéal serait donc :
</p>
<ul>
<li class="level1"><div class="li"> Des traces d&#039;évènement dans les log système</div>
</li>
<li class="level1"><div class="li"> Un script d&#039;alerte perso.</div>
</li>
</ul>

<p>
Pour les logs système, si vous utilisez la ligne de commande suivante :
</p>
<pre class="code">mdadm --monitor --syslog --delay=1800 /dev/md0
#équivalent à mdadm --monitor -y --delay=1800 /dev/md0</pre>

<p>
Ou encore, via le fichier de configuration /etc/mdadm/mdadm.conf en ajoutant :
</p>
<pre class="code"># START_DAEMON:
#   should mdadm start the MD monitoring daemon during boot?
START_DAEMON=true

# DAEMON_OPTIONS:
#   additional options to pass to the daemon.
DAEMON_OPTIONS=&quot;--syslog&quot;</pre>

<p>
Cependant, le mieux et le plus intéressant reste un script maison. Plusieurs paramètres sont fournis par mdadm :
</p>
<ul>
<li class="level1"><div class="li"> $1 : chaîne de caractères décrivant ce qui s&#039;est passé repris parmi celle-ci :</div>
<ul>
<li class="level2"><div class="li"> SparesMissing : spare disque manquant</div>
</li>
<li class="level2"><div class="li"> Fail : un ou plusieurs disques défectueux</div>
</li>
<li class="level2"><div class="li"> RebuildStarted : un nouveau disque est présent et une reconstruction a débuté</div>
</li>
<li class="level2"><div class="li"> Rebuild20, 40, 60, 80 : reconstruction en cours à 20, 40, 60 ou 80%</div>
</li>
<li class="level2"><div class="li"> RebuildFinished : la reconstruction vient de finir</div>
</li>
<li class="level2"><div class="li"> SpareActive : disque spare vient d&#039;être ajouté à un array</div>
</li>
</ul>
</li>
<li class="level1"><div class="li"> $2 : nom du disque raid md concerné, par exemple /dev/md2</div>
</li>
<li class="level1"><div class="li"> $3 : disque concerné, par exemple /dev/sda5</div>
</li>
</ul>

<p>
Un exemple de programme se trouve localement
</p>

<p>
Pour tester son programme on peut utiliser ceci :
</p>
<pre class="code">sudo mdadm --monitor --scan --oneshot --test --program /cheminversmonprogramme</pre>

<p>
Afin de l&#039;ajouter, 2 chemins sont possibles :
ligne de commande, si vous lancez le RAID de cette manière :
</p>
<pre class="code">mdadm --monitor --alert /cheminversmonprogramme --delay=180 /dev/md0
#ou -p ou --programm
#par defaut le delay est de 60 secondes</pre>

<p>
Ou encore, via le fichier de configuration /etc/mdadm/mdadm.conf en ajoutant :
</p>
<pre class="code"># PROGRAM
# programme qui sera exécuté en cas d&#039;évènement
PROGRAM /cheminversmonprogramme</pre>

</div>
<!-- EDIT26 SECTION "Supervision du RAID" [25623-27992] -->
<h3 class="sectionedit27" id="creation_d_un_raid_sans_avoir_tous_les_disques">Création d&#039;un RAID sans avoir tous les disques</h3>
<div class="level3">

<p>
Il est possible de créer un RAID sans avoir tous les disques au moment de la création. Pour cela au lieu de préciser /dev/sdXY on mettra missing.
Par exemple, dans le cas ci-dessous il faudra ajouter un disque plus tard :
</p>
<pre class="code">mdadm -C /dev/md0 -l1 -n2 /dev/sda1 missing</pre>

<p>
N.B.:
</p>

<p>
Pour créer un RAID 10 avec seulement deux disques, les deux autres disques, marqués comme manquants, devront être alternés avec ceux présents :
</p>
<pre class="code">mdadm --create /dev/md0 --level=10 --raid-devices=4 /dev/sda1 missing  /dev/sdb1 missing</pre>

<p>
Si l&#039;on met deux missing à la suite, cela ne fonctionne pas
</p>

<p>
Ensuite il suffit d&#039;ajouter le (ou les) disque(s) manquant(s) via :
</p>
<pre class="code">mdadm --manage /dev/md0 --add /dev/sdb1</pre>

<p>
Attention, ne pas oublier de regarder que la reconstruction du disque est finie *AVANT* de redémarrer, via 
</p>
<pre class="code">cat /proc/mdstat</pre>

</div>
<!-- EDIT27 SECTION "Création d'un RAID sans avoir tous les disques" [27993-28920] -->
<h3 class="sectionedit28" id="creation_d_un_raid1_sans_avoir_tous_les_disques_et_sans_copie">Création d&#039;un RAID1 sans avoir tous les disques et sans copie</h3>
<div class="level3">

<p>
Dans l&#039;exemple qui suit, on va mettre la partition /dev/sda4 en mirroir avec la partition /dev/sdb4. Cette procédure ne fait pas appel au rsync pour la copie, mais utilise la recopie du mdadm. Ce qui permet une remise en service plus rapide.
</p>

<p>
L&#039;exemple est fait pour une partition en ext2/ext3/ext4. Pour le reiserfs c&#039;est aussi faisable mail il faut ajuster les commandes (resize_reiserfs au lieu de e2fsck et resize2fs)
</p>

<p>
On démonte le file system, puis on calcule la nouvelle taile du file system car le RAID1 va rajoute un bloc de contrôle :
</p>
<pre class="code">
cd &amp;&amp; umount /dev/sda4
TAILLE_INITIAL=$(fdisk -l /dev/sda4 2&gt;/dev/null|grep &quot;/dev/sda4&quot; |cut -d &quot;,&quot; -f2| cut -d &quot; &quot; -f2)
TAILLE_F=$(( $(( TAILLE_INITIAL / 1024 )) - 12 ))K
echo $TAILLE_INITIAL
echo $TAILLE_F

e2fsck -f /dev/sda4
resize2fs /dev/sda4 $TAILLE_F</pre>

<p>
Ici a partition est prete a accueillir le bloc de controle du raid.
On construit le RAID
</p>
<pre class="code">mdadm --create /dev/md0 --metadata=1.0 --level=1 --raid-devices=2 missing /dev/sda4
	mdadm: /dev/sda4 appears to contain an ext2fs file system
		size=3979656K  mtime=Fri Mar 11 20:21:34 2011
	Continue creating array? y
	mdadm: array /dev/md0 started.

e2fsck -f /dev/md0
	e2fsck 1.41.12 (17-May-2010)
	La taille du système de fichiers (selon le superbloc) est de 525013 blocs
	La taille physique du périphérique est de 524992 blocs
	Le superbloc ou la table des partitions est peut-être corrompue !
	Arrêter&lt;o&gt;? non
	
	Passe 1 : vérification des i-noeuds, des blocs et des tailles
	Passe 2 : vérification de la structure des répertoires
	Passe 3 : vérification de la connectivité des répertoires
	Passe 4 : vérification des compteurs de référence
	Passe 5 : vérification de l&#039;information du sommaire de groupe
	DATA : 12/131376 fichiers (0.0% non contigus), 156488/525012 blocs</pre>

<p>
On resize le disque au cas où mais cela ne devrait pas être utile. S&#039;il indique qu&#039;il fait une modification c&#039;est que le calcul de TAILLE_F étati insufisant.
</p>
<pre class="code">resize2fs /dev/md0
resize2fs 1.41.12 (17-May-2010)
Le système de fichiers a déjà 525010 blocs. Rien à modifier !</pre>

<p>
On finit en marquant le disque comme étant un raid et on sauvegarde la configuration
</p>
<pre class="code">	~# sfdisk --id /dev/sda 4 fd
	
	~# cp -a /etc/mdadm/mdadm.conf /etc/mdadm/mdadm.conf.origin
	~# mdadm --misc --detail --brief /dev/md0 | tee -a /etc/mdadm/mdadm.conf</pre>

<p>
Vérification du status :
</p>
<pre class="code">	~# cat /proc/mdstat 
	Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
	md0 : active (read-only) raid1 sda4[1]
	      3979584 blocks [2/1] [_U]

	~# blkid /dev/md0
	/dev/md0: LABEL=&quot;DATA&quot; UUID=&quot;ff1521f6-e70d-4134-bb33-fb9f555ff6c5&quot; TYPE=&quot;ext4&quot;
	# le raid à bien hérité du File system et du nom

	# on vérifie qu&#039;une entrée pour le RAID existe dans le ficher de configuration
	tail /etc/mdadm/mdadm.conf</pre>

<p>
Mise en miroir : à partir du moment que le deuxième disque est disponible :
</p>
<pre class="code">
	~# mdadm --add /dev/md0 /dev/sdb4</pre>

<p>
On suit la reconstruction
</p>
<pre class="code">
	watch &quot;cat /proc/mdstat&quot;
	Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
	md0 : active raid1 sdb4[2] sda4[1]
	      3152192 blocks [2/1] [_U]
	      [&gt;....................]  recovery =  4.5% (144384/3152192) finish=0.6min speed=72192K/sec</pre>

</div>
<!-- EDIT28 SECTION "Création d'un RAID1 sans avoir tous les disques et sans copie" [28921-32321] -->
<h2 class="sectionedit29" id="un_peu_de_reference">Un peu de référence</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Comme toujours, une fois le paquet installé, de la doc est disponible localement</div>
</li>
<li class="level1"><div class="li"> <a href="http://svn.debian.org/wsvn/pkg-mdadm/mdadm/trunk/debian/FAQ?op=file&amp;rev=0&amp;sc=0" class="urlextern" title="http://svn.debian.org/wsvn/pkg-mdadm/mdadm/trunk/debian/FAQ?op=file&amp;rev=0&amp;sc=0"  rel="nofollow">FAQ de Debian sur mdadm</a></div>
</li>
<li class="level1"><div class="li"> <a href="https://raid.wiki.kernel.org/index.php/Linux_Raid" class="urlextern" title="https://raid.wiki.kernel.org/index.php/Linux_Raid"  rel="nofollow">Wiki de référence du raid logiciel Linux (à partir du kernel 2.6)</a></div>
</li>
<li class="level1"><div class="li"> <a href="http://tldp.org/HOWTO/Software-RAID-HOWTO.html" class="urlextern" title="http://tldp.org/HOWTO/Software-RAID-HOWTO.html"  rel="nofollow">How-TO complet sur la question du raid (kernel antérieur à 2.6)</a></div>
</li>
<li class="level1"><div class="li"> <a href="http://www.noisette.ch/wiki/index.php/Mdadm" class="urlextern" title="http://www.noisette.ch/wiki/index.php/Mdadm"  rel="nofollow">http://www.noisette.ch/wiki/index.php/Mdadm</a></div>
</li>
<li class="level1"><div class="li"> <a href="http://kev.coolcavemen.com/tag/mdadm/" class="urlextern" title="http://kev.coolcavemen.com/tag/mdadm/"  rel="nofollow">http://kev.coolcavemen.com/tag/mdadm/</a></div>
</li>
</ul>

<p>
—-
</p>

<p>
<em>Contributeurs : <a href="../../utilisateurs/goldkey" class="wikilink2" title="utilisateurs:goldkey" rel="nofollow">goldkey</a>, <a href="../../utilisateurs/deejc" class="wikilink1" title="utilisateurs:deejc">Deejc</a>, <a href="http://doc.ubuntu-fr.org/utilisateurs/grummfy" class="wikilink1" title="utilisateurs:grummfy">Grummfy</a>, gene69, David Schwindenhammer.</em>
</p>

</div>
<!-- EDIT29 SECTION "Un peu de référence" [32322-] -->
<!-- cachefile /srv/www/doc.ubuntu-fr.org/htdocs/data/cache/2/2e66d5f4bd83c5ef140d91ad8efe51d1.xhtml used -->
</div>
</body>
</html>
